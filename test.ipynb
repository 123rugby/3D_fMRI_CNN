{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training TF net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/braintree/home/bashivan/dropbox/Codes/3D_fMRI_CNN/tf_pipeline/')\n",
    "import os\n",
    "from tf_trainer import Trainer\n",
    "import logging \n",
    "from tf_model import TFModel\n",
    "from tf_dataset import TFDataset\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0,2'\n",
    "\n",
    "FLAGS.initial_learning_rate = 0.001\n",
    "FLAGS.batch_size = 64\n",
    "FLAGS.num_gpus = 2\n",
    "FLAGS.num_epochs_per_decay = 3\n",
    "FLAGS.num_time_steps = 64\n",
    "\n",
    "fold_to_run = 0\n",
    "\n",
    "# Load the dataset\n",
    "fold_pairs = []\n",
    "\n",
    "model = TFModel()\n",
    "dataset = TFDataset(data_dir='/braintree/data2/active/users/bashivan/Data/fmri_conv_orig/')\n",
    "tr = Trainer(model=model, dataset=dataset)\n",
    "print(\"Loading data...\")\n",
    "tr.load_data(random=False)\n",
    "\n",
    "sub_nums = tr.subjects\n",
    "subs_in_fold = np.ceil(np.max(sub_nums) / float(10))\n",
    "# n-fold cross validation\n",
    "for i in range(FLAGS.num_folds):\n",
    "    '''\n",
    "    for each kfold selects fold window to collect indices for test dataset and the rest becomes train\n",
    "    '''\n",
    "    test_ids = np.bitwise_and(sub_nums >= subs_in_fold * (i), sub_nums < subs_in_fold * (i + 1))\n",
    "    train_ids = ~ test_ids\n",
    "    fold_pairs.append((np.nonzero(train_ids)[0], np.nonzero(test_ids)[0]))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting the data...\n",
      "Preprocessing data...\n"
     ]
    }
   ],
   "source": [
    "FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "fold_num = 0\n",
    "fold = fold_pairs[0]\n",
    "\n",
    "FLAGS.train_dir = os.path.join(FLAGS.train_dir, str(fold_num))\n",
    "\n",
    "print('Splitting the data...')\n",
    "tr.split_data(fold)\n",
    "print('Preprocessing data...')\n",
    "tr.preprocess_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************\n",
      "subset: train\n",
      "data_dir: /braintree/data2/active/users/bashivan/Data/fmri_conv_orig\n",
      "num_epochs_per_decay: 3\n",
      "num_gpus: 2\n",
      "train_dir: /braintree/data2/active/users/bashivan/results/temp/0\n",
      "batch_size: 64\n",
      "model_type: lstm\n",
      "num_checkpoints_tosave: 5\n",
      "initial_learning_rate: 0.001\n",
      "num_examples: None\n",
      "num_epochs: 10\n",
      "checkpoint_dir: .\n",
      "learning_rate_decay_factor: 0.1\n",
      "fold_to_run: -1\n",
      "num_folds: 10\n",
      "seed: 0\n",
      "eval_dir: /om/user/bashivan/temp\n",
      "num_time_steps: 64\n",
      "log_device_placement: False\n",
      "****************************************\n",
      "> /braintree/home/bashivan/dropbox/Codes/3D_fMRI_CNN/tf_pipeline/tf_dataset.py(18)num_examples_per_epoch()\n",
      "-> if subset == 'train':\n",
      "(Pdb) (self._features.shape[0] / FLAGS.num_folds * (FLAGS.num_folds - 2)) * \\              (self._features.shape[-1] - FLAGS.num_time_steps)\n",
      "*** SyntaxError: unexpected character after line continuation character (<stdin>, line 1)\n",
      "(Pdb) (self._features.shape[0] / FLAGS.num_folds * (FLAGS.num_folds - 2)) * (self._features.shape[-1] - FLAGS.num_time_steps)\n",
      "22192\n",
      "(Pdb) (self._features.shape[-1] - FLAGS.num_time_steps)\n",
      "73\n",
      "(Pdb) c\n",
      "Using ADAM optimizer...\n",
      "Using default loss (softmax-Xentropy)...\n",
      "WARNING:tensorflow:From /braintree/home/bashivan/dropbox/Codes/3D_fMRI_CNN/tf_pipeline/tf_model.py:205: softmax_cross_entropy (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.\n",
      "Instructions for updating:\n",
      "Use tf.losses.softmax_cross_entropy instead. Note that the order of the logits and labels arguments has been changed.\n",
      "WARNING:tensorflow:From /braintree/home/bashivan/anaconda2/envs/dldata/lib/python2.7/site-packages/tensorflow/contrib/losses/python/losses/loss_ops.py:398: compute_weighted_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.\n",
      "Instructions for updating:\n",
      "Use tf.losses.compute_weighted_loss instead.\n",
      "WARNING:tensorflow:From /braintree/home/bashivan/anaconda2/envs/dldata/lib/python2.7/site-packages/tensorflow/contrib/losses/python/losses/loss_ops.py:151: add_loss (from tensorflow.contrib.framework.python.ops.arg_scope) is deprecated and will be removed after 2016-12-30.\n",
      "Instructions for updating:\n",
      "Use tf.losses.add_loss instead.\n",
      "total_params: 185650\n",
      "Using default loss (softmax-Xentropy)...\n",
      "WARNING:tensorflow:From /braintree/home/bashivan/dropbox/Codes/3D_fMRI_CNN/tf_pipeline/tf_model.py:205: softmax_cross_entropy (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.\n",
      "Instructions for updating:\n",
      "Use tf.losses.softmax_cross_entropy instead. Note that the order of the logits and labels arguments has been changed.\n",
      "WARNING:tensorflow:From /braintree/home/bashivan/anaconda2/envs/dldata/lib/python2.7/site-packages/tensorflow/contrib/losses/python/losses/loss_ops.py:398: compute_weighted_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.\n",
      "Instructions for updating:\n",
      "Use tf.losses.compute_weighted_loss instead.\n",
      "WARNING:tensorflow:From /braintree/home/bashivan/anaconda2/envs/dldata/lib/python2.7/site-packages/tensorflow/contrib/losses/python/losses/loss_ops.py:151: add_loss (from tensorflow.contrib.framework.python.ops.arg_scope) is deprecated and will be removed after 2016-12-30.\n",
      "Instructions for updating:\n",
      "Use tf.losses.add_loss instead.\n",
      "total_params: 185650\n",
      "2017-08-16 17:10:51.776636: step 0, loss = 0.69 (13.5 examples/sec; 4.730 sec/batch)\n",
      "2017-08-16 17:11:24.593265: step 100, loss = 0.69 (242.0 examples/sec; 0.264 sec/batch)\n",
      "2017-08-16 17:11:52.364206: step 200, loss = 0.59 (240.9 examples/sec; 0.266 sec/batch)\n",
      "2017-08-16 17:12:20.140099: step 300, loss = 0.66 (249.1 examples/sec; 0.257 sec/batch)\n",
      "Epoch 1 of 10 took 112.833s\n",
      "  training loss:\t\t0.662330\n",
      "  training accuracy:\t\t60.49 %\n",
      "  validation loss:\t\t0.694354\n",
      "  validation accuracy:\t\t83.96 %\n",
      "Test results:\n",
      "  test loss:\t\t\t0.617890\n",
      "  test accuracy:\t\t65.24 %\n",
      "2017-08-16 17:12:58.556158: step 400, loss = 0.57 (232.1 examples/sec; 0.276 sec/batch)\n",
      "2017-08-16 17:13:27.559097: step 500, loss = 0.61 (241.0 examples/sec; 0.266 sec/batch)\n",
      "2017-08-16 17:13:56.590226: step 600, loss = 0.54 (233.8 examples/sec; 0.274 sec/batch)\n",
      "2017-08-16 17:14:26.039074: step 700, loss = 0.41 (241.8 examples/sec; 0.265 sec/batch)\n",
      "Epoch 2 of 10 took 106.766s\n",
      "  training loss:\t\t0.593741\n",
      "  training accuracy:\t\t70.71 %\n",
      "  validation loss:\t\t1.544018\n",
      "  validation accuracy:\t\t41.54 %\n",
      "2017-08-16 17:15:00.142525: step 800, loss = 0.68 (215.4 examples/sec; 0.297 sec/batch)\n",
      "2017-08-16 17:15:29.643117: step 900, loss = 0.62 (209.6 examples/sec; 0.305 sec/batch)\n",
      "2017-08-16 17:15:59.413844: step 1000, loss = 0.65 (212.9 examples/sec; 0.301 sec/batch)\n",
      "Epoch 3 of 10 took 112.574s\n",
      "  training loss:\t\t0.623600\n",
      "  training accuracy:\t\t67.70 %\n",
      "  validation loss:\t\t0.762987\n",
      "  validation accuracy:\t\t75.34 %\n",
      "2017-08-16 17:16:38.030774: step 1100, loss = 0.36 (234.2 examples/sec; 0.273 sec/batch)\n",
      "2017-08-16 17:17:07.582635: step 1200, loss = 0.42 (241.2 examples/sec; 0.265 sec/batch)\n",
      "2017-08-16 17:17:37.354158: step 1300, loss = 0.35 (235.9 examples/sec; 0.271 sec/batch)\n",
      "2017-08-16 17:18:07.400519: step 1400, loss = 0.38 (238.3 examples/sec; 0.269 sec/batch)\n",
      "Epoch 4 of 10 took 109.397s\n",
      "  training loss:\t\t0.403577\n",
      "  training accuracy:\t\t88.39 %\n",
      "  validation loss:\t\t0.829326\n",
      "  validation accuracy:\t\t68.71 %\n",
      "2017-08-16 17:18:41.839190: step 1500, loss = 0.29 (235.0 examples/sec; 0.272 sec/batch)\n",
      "2017-08-16 17:19:11.620520: step 1600, loss = 0.22 (228.0 examples/sec; 0.281 sec/batch)\n",
      "2017-08-16 17:19:42.003614: step 1700, loss = 0.39 (222.2 examples/sec; 0.288 sec/batch)\n",
      "Epoch 5 of 10 took 109.683s\n",
      "  training loss:\t\t0.304646\n",
      "  training accuracy:\t\t94.48 %\n",
      "  validation loss:\t\t0.946587\n",
      "  validation accuracy:\t\t64.67 %\n",
      "2017-08-16 17:20:16.517957: step 1800, loss = 0.21 (242.2 examples/sec; 0.264 sec/batch)\n",
      "2017-08-16 17:20:46.626264: step 1900, loss = 0.21 (225.3 examples/sec; 0.284 sec/batch)\n",
      "2017-08-16 17:21:16.514869: step 2000, loss = 0.23 (204.0 examples/sec; 0.314 sec/batch)\n",
      "2017-08-16 17:21:50.318989: step 2100, loss = 0.28 (219.9 examples/sec; 0.291 sec/batch)\n",
      "Epoch 6 of 10 took 113.895s\n",
      "  training loss:\t\t0.254550\n",
      "  training accuracy:\t\t97.60 %\n",
      "  validation loss:\t\t1.061689\n",
      "  validation accuracy:\t\t57.13 %\n",
      "2017-08-16 17:22:25.068830: step 2200, loss = 0.30 (217.4 examples/sec; 0.294 sec/batch)\n",
      "2017-08-16 17:22:55.307884: step 2300, loss = 0.21 (236.9 examples/sec; 0.270 sec/batch)\n",
      "2017-08-16 17:23:25.323761: step 2400, loss = 0.21 (236.7 examples/sec; 0.270 sec/batch)\n",
      "Epoch 7 of 10 took 109.988s\n",
      "  training loss:\t\t0.235198\n",
      "  training accuracy:\t\t98.70 %\n",
      "  validation loss:\t\t1.017435\n",
      "  validation accuracy:\t\t60.82 %\n",
      "2017-08-16 17:23:59.827308: step 2500, loss = 0.22 (232.8 examples/sec; 0.275 sec/batch)\n",
      "2017-08-16 17:24:29.804836: step 2600, loss = 0.22 (218.6 examples/sec; 0.293 sec/batch)\n",
      "2017-08-16 17:24:59.847773: step 2700, loss = 0.22 (224.6 examples/sec; 0.285 sec/batch)\n",
      "2017-08-16 17:25:30.097143: step 2800, loss = 0.21 (230.4 examples/sec; 0.278 sec/batch)\n",
      "Epoch 8 of 10 took 110.316s\n",
      "  training loss:\t\t0.229411\n",
      "  training accuracy:\t\t99.02 %\n",
      "  validation loss:\t\t1.162993\n",
      "  validation accuracy:\t\t54.50 %\n",
      "2017-08-16 17:26:04.776865: step 2900, loss = 0.22 (234.6 examples/sec; 0.273 sec/batch)\n",
      "2017-08-16 17:26:34.523889: step 3000, loss = 0.26 (235.4 examples/sec; 0.272 sec/batch)\n",
      "2017-08-16 17:27:08.636670: step 3100, loss = 0.27 (213.8 examples/sec; 0.299 sec/batch)\n",
      "Epoch 9 of 10 took 113.748s\n",
      "  training loss:\t\t0.230157\n",
      "  training accuracy:\t\t98.94 %\n",
      "  validation loss:\t\t1.008348\n",
      "  validation accuracy:\t\t60.48 %\n",
      "2017-08-16 17:27:43.208223: step 3200, loss = 0.22 (220.5 examples/sec; 0.290 sec/batch)\n",
      "2017-08-16 17:28:13.153692: step 3300, loss = 0.22 (208.1 examples/sec; 0.308 sec/batch)\n",
      "2017-08-16 17:28:43.100620: step 3400, loss = 0.22 (227.0 examples/sec; 0.282 sec/batch)\n",
      "2017-08-16 17:29:13.362930: step 3500, loss = 0.27 (231.9 examples/sec; 0.276 sec/batch)\n",
      "Epoch 10 of 10 took 110.032s\n",
      "  training loss:\t\t0.227268\n",
      "  training accuracy:\t\t99.13 %\n",
      "  validation loss:\t\t1.044832\n",
      "  validation accuracy:\t\t58.69 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr.train(fold_num=fold_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'test_acc', u'test_loss', u'training_acc', u'training_loss',\n",
       "       u'valid_acc', u'valid_loss'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cPickle\n",
    "data = cPickle.load(open('/braintree/home/bashivan/dropbox/Codes/3D_fMRI_CNN/cnn_lstm_results_adam_0.0001_10fold_.pkl'))\n",
    "\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.553496\n",
       "1    0.607521\n",
       "2    0.607521\n",
       "3    0.627913\n",
       "4    0.627913\n",
       "Name: test_acc, dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['test_acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
